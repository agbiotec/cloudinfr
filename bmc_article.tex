%% BioMed_Central_Tex_Template_v1.05
%%                                      %
%  bmc_article.tex            ver: 1.05 % %


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                     %%
%%  LaTeX template for BioMed Central  %%
%%     journal article submissions     %%
%%                                     %%
%%         <27 January 2006>           %%
%%                                     %%
%%                                     %%
%% Uses:                               %%
%% cite.sty, url.sty, bmc_article.cls  %%
%% ifthen.sty. multicol.sty		       %%
%%									   %%
%%                                     %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                                                 %%	
%% For instructions on how to fill out this Tex template           %%
%% document please refer to Readme.pdf and the instructions for    %%
%% authors page on the biomed central website                      %%
%% http://www.biomedcentral.com/info/authors/                      %%
%%                                                                 %%
%% Please do not use \input{...} to include other tex files.       %%
%% Submit your LaTeX manuscript as one .tex document.              %%
%%                                                                 %%
%% All additional figures and files should be attached             %%
%% separately and not embedded in the \TeX\ document itself.       %%
%%                                                                 %%
%% BioMed Central currently use the MikTex distribution of         %%
%% TeX for Windows) of TeX and LaTeX.  This is available from      %%
%% http://www.miktex.org                                           %%
%%                                                                 %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\NeedsTeXFormat{LaTeX2e}[1995/12/01] \documentclass[10pt]{bmc_article}    



% Load packages
\usepackage{cite} % Make references as [1-4], not [1,2,3,4] \usepackage{url}  % Formatting web addresses
\usepackage{ifthen}  % Conditional \usepackage{multicol}   %Columns \usepackage[utf8]{inputenc} %unicode support
%\usepackage[applemac]{inputenc} %applemac support if unicode package fails \usepackage[latin1]{inputenc}
%%UNIX support if unicode package fails \urlstyle{rm}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%	
%%                                             %%
%%  If you wish to display your graphics for   %%
%%  your own use using includegraphic or       %%
%%  includegraphics, then comment out the      %%
%%  following two lines of code.               %%   
%%  NB: These line *must* be included when     %%
%%  submitting to BMC.                         %% 
%%  All figure files must be submitted as      %%
%%  separate graphics through the BMC          %%
%%  submission process, not included in the    %% 
%%  submitted article.                         %% 
%%                                             %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%                     


\def\includegraphic{} \def\includegraphics{}



\setlength{\topmargin}{0.0cm} \setlength{\textheight}{21.5cm} \setlength{\oddsidemargin}{0cm}
\setlength{\textwidth}{16.5cm} \setlength{\columnsep}{0.6cm}

\newboolean{publ}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                              %%
%% You may change the following style settings  %%
%% Should you wish to format your article       %%
%% in a publication style for printing out and  %%
%% sharing with colleagues, but ensure that     %%
%% before submitting to BMC that the style is   %%
%% returned to the Review style setting.        %%
%%                                              %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


%Review style settings
\newenvironment{bmcformat}{\begin{raggedright}\baselineskip20pt\sloppy\setboolean{publ}{false}}{\end{raggedright}\baselineskip20pt\sloppy}

%Publication style settings \newenvironment{bmcformat}{\fussy\setboolean{publ}{true}}{\fussy}



% Begin ...
\begin{document} \begin{bmcformat}


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the title of your article here     %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\title{Six Questions and Answers Defining Cloud Computing for Digital, Sequencing-Based Biological Research}

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors here                   %%
%%                                          %%
%% Ensure \and is entered between all but   %%
%% the last two authors. This will be       %%
%% replaced by a comma in the final article %%
%%                                          %%
%% Ensure there are no trailing spaces at   %% 
%% the ends of the lines                    %%     	
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\author{Konstantinos Krampis\correspondingauthor$^{1}$% \email{Konstantinos Krampis\correspondingauthor -
agbiotec@gmail.com}% }


%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% Enter the authors' addresses here        %%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%

\address{% \iid(1)Informatics Department, J. Craig Venter Institute, 9704 Medical Center Dr. ,% Rockville, MD
20850, USA }%

\maketitle

%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Abstract begins here                 %%
%%                                          %%
%% The Section headings here are those for  %%
%% a Research article submitted to a        %%
%% BMC-Series journal.                      %%  
%%                                          %%
%% If your article is not of this type,     %%
%% then refer to the Instructions for       %%
%% authors on http://www.biomedcentral.com  %%
%% and change the section headings          %%
%% accordingly.                             %%   
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


\begin{abstract}
% Do not use inserted blank lines (ie \\) until main body of text.
\paragraph*{Background:} Text for this section of the abstract. \cite{Metzker2009} 

\paragraph*{Results:} Text for this section of the abstract \ldots

\paragraph*{Conclusions:} Text for this section of the abstract \ldots \end{abstract}



\ifthenelse{\boolean{publ}}{\begin{multicols}{2}}{}




%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                                          %%
%% The Main Body begins here                %%
%%                                          %%
%% The Section headings here are those for  %%
%% a Research article submitted to a        %%
%% BMC-Series journal.                      %%  
%%                                          %%
%% If your article is not of this type,     %%
%% then refer to the instructions for       %%
%% authors on:                              %%
%% http://www.biomedcentral.com/info/authors%%
%% and change the section headings          %%
%% accordingly.                             %% 
%%                                          %%
%% See the Results and Discussion section   %%
%% for details on how to create sub-sections%%
%%                                          %%
%% use \cite{...} to cite references        %%
%%  \cite{koon} and                         %%
%%  \cite{oreg,khar,zvai,xjon,schn,pond}    %%
%%  \nocite{smith,marg,hunn,advi,koha,mouse}%%
%%                                          %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%



%%%%%%%%%%%%%%%%
%% Background %%
%%
\section*{Background}
\subsubsection*{Next-Gen Sequencing, Cloud Computing, and The Digital Biology Research} 

Advances in high-throughput sequencing and the synthesis of genomes has defined "The Digital Age of Biology" 
\cite{venterdublin}, where we have transitioned from the vision of Schrodinger that "Life is code" \cite{Schrodinger1992} 
to applied processes that convert digital code into DNA that runs a living organism \cite{Gibson2010}.

In recent years sequencing technologies continue to move in a direction where throughput per run is increasing while cost
per basepair is decreasing (review in \cite{Mason2012}).  Several technologies available on the market today
produce massive volumes of sequence data; for instance, one of the most widely used instruments in the
field currently and for the past few years, Illumina's GAIIx system can produce up to 95 Giga-base (Gb) of 
sequence per run \cite{Illumina} while the also broadly used SOLiD sequencer has yields of a similar range up to
90 Gb \cite{solid5500}. With the latest generation of instruments such as for example the HiSeq system, yield
per run has reached 600 Gb \cite{Illumina}, while the Pacific BioSciences sequencer yields 90 Gb in short amounts
of time \cite{PacBio}. \pb

Recently, small-factor, benchtop sequencers became available all of which can be acquired at a fraction of the 
cost and be affordable for independent researchers running smaller laboratories. Examples in this category
include GS Junior by 454, MiSeq by Illumina and Ion Proton by Life Technologies, providing sequencing 
capacity at 0.035Gb, 1Gb and 1.5Gb respectively for GS Junior, Ion Proton and MiSeq review in \cite{Loman2012}) 
that is adequate for sequencing bacterial, small fungal or viral genomes. Taking this fact into account along with
low cost per run (US \$225 -\$1100 depending on which benchtop sequencer is used and required throughput), 
sequencing has already started becoming a standard technique for basic biological research performed in smaller
laboratories.  Example applications of sequencing in biological research include Single Nucleotide Polymorphism 
(SNP) variation discovery , gene expression analysis (RNAseq) and DNA-protein interaction analysis
(ChiPseq), (review in \cite{Mardis2008}).

The new generation of sequencing technologies is also being used in the area of metagenomics, for large-scale
studies of uncultivated microbial communities. The J.  Craig Venter Institute (JCVI) for example has been
involved in several such metagenomic projects, including the Sorcerer II Global Ocean Sampling (GOS,
\cite{Rusch2007}) expedition to study marine microbial diversity, and also the National Institutes of Health
funded Human Microbiome Project to study human associated microbial communities \cite{Nelson2010}. \pb

While large datasets are generated sequencers, these instruments are typically bundled with only minimal
computational and storage capacity for data capture during a sequencing run.  For example, the un-assembled reads
returned from a single lane of the Illumina GAIIx instrument after base calling are approximately 100 GigaByte
(GB) in size. For small laboratories acquiring a sequencing instrument, the currently available online software tools are
not and option for downstream sequence analysis, since they cannot provide the required compute capacity. The
NCBI website for example \cite{johnson2008ncbi}, cannot accept input sequence data files of more than 0.5 GB
size for BLAST sequence simijarity search. With this as an example, we see that scientific value cannot be
obtained from investment in a sequencing instrument, unless it is accompanied by an almost equal or greater
investment in informatics hardware infrastructure. Besides large capacity computing servers, also required are
trained bioinformaticians competent to install, configure and use specific software to analyze the generated
data, and store the data in appropriate formats for future use.  \pb

Due to the nature of next-generation sequencing data analysis, computationally intensive tasks of genome
assembly or whole genome alignments that require extensive compute resources, alternate with tasks such as 
genome annotation that are less computationally demanding. This leads to sub-optimal utilization of computer 
hardware installed within bioinformatic data centers, while maintenance costs including electricity, cooling and
informatics support personnel salaries stay at constant levels. For smaller academic institutions this can pose an
impendiment for leveraging sequencing technology for research, as in addition to securing the funds for building 
a cluster with adequate capacity to handle large-scale genomic datasets, they also need to maintain a system 
that is not utilized at its full capacity most of the time.  A second complication is related to the fact that 
databases with reference genomes \cite{Pruitt2009} are constantly growing in size, and for most bioinformatic analysis they need 
to be downloaded to local storage systems, in order to be used as for example when conducting comparative 
genome annotations. As these databases grow larger the process becomes more time consuming, incurring in higher 
bandwidth and storage costs for replicating the data locally.  Finally, building a data analysis infrastructure 
for next-generation sequencing also involves hiring trained bioinformatics engineers competent to install, 
configure and use specialized software tools and data analysis pipelines, which in the end can result to 
higher expenses than that of acquiring the computer hardware or maintaining the data center. \pb



%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%% Results and Discussion %%
%%

\section*{Results and Discussion}
\subsection*{Six Questions and Answers to Define Cloud Computing Applications for Digital, Sequencing-Based Biological Research} 

\subsubsection*{What Role can Cloud Computing play in The Digital Biology Research Era?}

As an alternative to building local informatics infrastructure at their laboratories, researchers can rent 
computational and storage capacity from cloud services such as Amazon EC2 \cite{awsec2}. This can potentially be
a better economic model for smaller research laboratories, since the cost for hardware and data center 
maintenance cannot be justified for only a few sequencing experiments. The Amazon EC2 Cloud service for example, 
employs a charge model similar to traditional utilities such as electricity, and users 
renting servers are billed based on the amount of computational capacity consumed on an hourly basis \cite{ec2price}. 
This Cloud service consists of thousands of computer servers with petabytes of storage, leveraging economies of 
scale to achieve low operational costs that in turn offers as savings to users. Furthermore, the Amazon Cloud 
has data centers in US East and West regions, European Union and Asia \cite{ec2regions}, providing researchers 
worldwide with the ability to tap into a large pool of computational resources, outside of institutional, 
economic or geographic boundaries. Overall, renting computational capacity from Cloud services has the 
potential to eliminate many of the upfront capital expenses for building information technology infrastructures 
for next generation sequencing, and result in transformation of the analysis and data processing tasks into well 
defined operational costs. 

The current approach of data warehousing in public databases such as the Sequence Read Archive (SRA,\cite{sra}) 
provides little value to researchers that lack access to computational resources or informatics expertise. Leveraging
the value of these or other genomic datasets deposited on public databases, requires multiple steps including downloading
the data, provisioning high-performance computer servers and large-scale data storage, in addition to compiling and 
installing specialized bioinformatics software. For scientists that do not have access to computing infrastructures, 
alternative approaches are required in order to be able to analyze sequencing datasets generated locally at their
laboratories, and to add scientific value by integrating with genomic data from other studies available on public databases.
A project that has demonstrated distributing genomic datasets in combination with computational capacity, and essentially 
placing data where the compute cycles are, is the 1000 Human genomes project \cite{clarke2012}. In this example, sequence
read data have been deposited on Amazon Cloud storage that is directly accessible by rented servers on the same Cloud, 
allowing analysis using pre-installed bioinformatics software from the Cloud BioLinux project \cite{Krampis2012}, 
\cite{1000tube1}, \cite{1000tube2}. 

Computational analysis can be a the major bottleneck for smaller laboratories and academic institutes transitioning 
experimental techniques used for basic biology research to sequencing-based methods, including for example RNAseq for 
gene expression, ChipSeq for protein interactions, metagenomics for microbial population analysis. Furthermore, as 
sequencing capacities follow an uptrend that surpasses that of Moore's Law \cite{Meyer2006} while the cost per base pair follows
an inverted trend, the genomics community can easily undertake projects at similar scales to that of the 1000 human 
genomes project. By placing such datasets on publicly accessible Cloud compute platforms, their value for other 
researchers in the community is immediatelly increased, reducing the number of required steps for scientific 
discovery to simply uploading their data on the Cloud storage and running analysis pipelines using rented servers with 
pre-configured software from the Cloud service. 


Established research institutes that perform sequencing of new genomes on a regular basis, and consecutively have
well-funded bioinformatic cores to process the sequence data, have the resource and expertise to deliver to the community 
beyond the production of finished genomes at each center and their upload to publicly-accessible repositories such as 
NCBI \cite{Pruitt2009}. This can be achieved by capturing and distributing the bioinformatics expertise developed during each
sequencing project, by making publicly available on the Cloud and will contain all software and customized data analysis
pipelines developed for sequence analysis at each institute. Currently, many of these centers deposit developed 
software on open-source code repositories such as SourceForge \cite{sourceforge} or GitHub \cite{github}. One major 
bottleneck for community researchers leveraging these newly developed bioinformatics tools is the requirement to 
download and compile the code by first configuring all the dependencies including the type of operating system, code 
libraries and computer hardware used at the bioinformatics core where the software was originally developed. This 
creates an obstacle for laboratories lacking the required informatics expertise and computational infrastructure, 
that can be avoided by utilizing servers containing pre-configured bioinformatics tools. This approach in turn, can 
democratize access to computational resources requeired for high throughput sequencing data analysis and allow further 
adoption of sequencing technology for basic biology research. Specialized compute servers with bioinformatics tools 
and data pipelines available on the Cloud through the Amazon EC2 service for example, can provide publicly accessible, 
high performance data analysis platform for use by research groups acquiring sequencing capability, that can be rented 
on-demand at low cost, removing the need for implementing informatics infrastructure at each laboratory.  


\subsubsection*{Are Cloud-Based Bioinformatics Software Suites Available on the Cloud ?}
  
A number of systems for  deploying bioinformatics tools through community accessible web portals 
have been developed during the past decade, including the Biology Workbench \cite{Subramaniam1998Biology}, 
PISE \cite{Letondal2001Web}, wEMBOSS \cite{Sarachu2005WEMBOSS}, Mobyle \cite{Neron2009Mobyle}
BioManager \cite{Cattley2007BioManager} and BioExtract \cite{Lushbough2008Implementing}. Some 
of those systems are not actively developed anymore; most require significant software development effort 
and system customization in order to deploy the tools through the web interface; with the exception of Mobyle, 
none of these portals provides users with an intuitive option to create and edit complex data analysis workflows; 
users have the option to download the source code for each system, but need to provision the hardware and
software engineering expertise to install the portal on a compute server;  management and sharing of 
datasets among users is difficult, while available storage space is limited by the capacity of the server
where the portal is installed; finally, these portals do not leverage the Cloud's scalability but rather 
run on computational hardware with fixed capacity, that poses a limitation on the dataset size that can
be processed. 

On the other hand, web portals that can analyze large-scale bioinformatic datasets, have been developed by 
well-funded institutions including IMG/M \cite{Grigoriev2012}, CAMERA \cite{Altintas2010}, EBI \cite{Hunter2011} 
and MG-RAST \cite{Aziz2010}. While these portals are backed by considerable compute resources and data storage,  
due to their centralized approach they cannot possibly support the increasing numbers of laboratories that 
purchase benchtop sequencers and produce genomic datasets. Furthermore, researchers are required to go through 
an application process in order to get access for uploading their data and have allocated computational capacity  
for data analysis within their account. Another major drawback is that the software for most of these sites is not 
open-source, while researchers often have to perform multiple submitions of their datasets to all the different 
portals, since each offers a different sequence data analysis pipeline.   

An alternative to these centralized services are Cloud-based, scalable data analysis portals such as Galaxy
\cite{Goecks2010}, CloVR \cite{Angiuoli2011}, Cloud BioLinux \cite{Krampis2012} and BioKepler \cite{Altintas2011} 
that are open-source and accessible to any laboratory or research group through the Amazon EC2 computer Cloud 
\cite{awsec2}. The Galaxy bioinformatics workbench, includes a range of tools, from scripts that extract 
entries from sequence files, to software for processing next-generation sequence data. Galaxy is a self-contained 
platform including a web portal software stack and a set of bioinformatics tools with graphical user interfaces, 
in addition to an intuitive, drag and drop canvas for composing complex data analysis workflows. Galaxy was 
designed as a framework for easy deployment through a web portal of command-line only software that lacks a user 
interface, and for that purpose provides a standardized method to deploy through the web portal command-line only
bioinformatics tools with only minimal expertise for editing simple configuration files describing the interface 
\cite{galaxywiki}.  Furthermore, it allows to leverage computational capacity beyond a single compute server 
through the Galaxy-Cloudman \cite{Afgan2010} framework that provides compute clusters for parallel data processing 
on Cloud services such as Amazon EC2.

Another community-centered, public access offering for computing on the Cloud is through our own Cloud Biolinux \cite{Krampis2012},
\cite{cloudbio}, that provides on-demand bioinformatics computing and a set of pre-configured sequence analysis 
tools within a high-performance Virtual Machine (VM) server that runs on Cloud computing services such as Amazon 
EC2. The project is targeted to researchers that without access to large-scale informatics infrastructures
for sequencing data analysis, but can rent instead computational capacity from Cloud services. Users can access 
the tools by starting the Cloud BioLinux VM through the Amazon cloud console web page \cite{console}, and 
easily perform large-scale data analysis as we have demonstrated with the 1000 Human genomes data \cite{1000tube1},
\cite{1000tube2},\cite{Clarke2012}. 


The Cloud BioLinux VM is open-source, can be downloaded and modified, while advanced users can install and 
run it on a private instance of the Eucalyptus \cite{euca} or Openstack \cite{openstack} Cloud platforms. 
A diverse community of researchers from both the US
(Massachusetts General Hospital, Harvard School of Public Health, Emory University) and Europe (National
Environmental Research Center, King's College London, Denmark Technical University, Netherlands Wageninen
University) has been already established around the project \cite{googlegroup}. Finally, we have recently 
expanded Cloud BioLinux by adding support for advanced users through a developer's framework for building 
and distributing customized bioinformatics VMs, providing a toolkit for development of Cloud-based 
bioinformatics data analysis solutions. The framework includes a software management system that automates 
building a VM with a set of bioinformatics tools specified by the user and seamlessly deploys it across different
Cloud platforms. The framework is freely available from the GitHub code repository \cite{fabric}.  The overall goal is
to offer a platform for maintaining a range of specialized VM setups for serving different computing needs
within the bioinformatics community, and allow researchers to focus on the next challenges of providing data,
documentation, and the development of scalable analysis pipelines. 

The solutions presented above provide public access to scalable sequence analysis for the genomic community, 
and users can get access to pre-configured software and on-demand computing platforms using Cloud infrastructures.
While this is a great solution for smaller laboratories that lack informatics resources for sequencing data analysis,   
these cloud solutions simply offer within VM servers bioinformatics applications with monolithic designs that 
process data serially, and are not designed to leverage specific characteristics of Cloud computing platforms
such as highly parallelism and distributed computing.  On the other hand, specialized, high-performance bioinformatics 
applications and data pipelines that have been implemented by bioinformatics core teams at large institutions,
are usually coupled with specific cluster computing hardware and data storage infrastructure at each institution, 
requiring extended effort to refactor the code and run data analysis pipelines on the Cloud \cite{Wilkening2009}.


\subsubsection*{Unique characteristics of Cloud Computing versus traditional Bioinformatics Infrastructures}

One major component of cloud computing technology is virtualization \cite{Uhling2005} which allows entire 
compute servers including the operating system and all the necessary software packages for data analysis 
to be archived within a Virtual Machine (VM). A VM is an emulation of a compute server, with virtual 
processors, memory and storage capacity, in the form of a single binary file that can run 
independently of the underlying hardware architecture, on both Cloud and desktop computers. 
Since all software components and dependencies are encapsulated  within the VM, it is possible to 
distribute data analysis pipelines, databases, websites, in addition to all required code libraries and 
configuration files in a ready-to-execute, easy-to-download and compact format. This can address  
obstacles researchers often encounter when trying to install and use open-source bioinformatics software 
with complex dependencies and installation procedures, therefore making bioinformatics tools widely 
accessible to the research community. Cloud services such as Amazon EC2 \cite{awsec2} provide high-
performance computer hardware with a virtualization layer, where users can run VM servers. 

In our experience with development of bioinformatics projects, it is difficult to provide long-term 
support or maintain web portals with data analysis tools and online databases, especially 
for projects funded by government grants with an expiration date. Alternatively, by using Cloud VM servers
to build the system and subsequently creating Whole System Snapshots (WSSE,\cite{Dudley2010,
Krampis2012}) bioinformatics web portals and online databases that are build on the Cloud can be 
preserved in their precise state when the snapshot was created. A snapshot essentially is a compressed, 
exact replica of a VM, capturing all changes made inside a VM server up to the point in time when the 
snapshot is created. These changes include installed software and bioinformatic pipelines, uploaded data 
and analysis results generated by running the pipelines. A snapshot is an executable binary file like 
the original VM, and using a snapshot as template the virtualization meachanism of a Cloud platform 
can instantiate replicas of the VM servers. Furthermore, a user can set her snapshots to be publicly 
accessible within the Cloud or share for example with specific users (see for example \cite{ebs}), 
therefore sharing with collaborating researchers both the data and software tools in a ready to execute 
and compact format. 

Regarding cost, on Amazon EC2 for example VM snapshots cost \$0.01 US per GigaByte(GB) of storage used 
per month. We see therefore that even when renting capacity from cloud provider the cost is minimal, 
and Pricipal Investigators can allocate on their budgets an amount of informatics expenses that will 
allow maintaining VM server snapshots for a few years past the end of the funding cycle for a project 
involving data release online though a portal or website-accessible database. Unlike the traditional 
approach where websites are decommissioned shortly
after the funding for a project ends, with this approach researchers in the community become able to 
lease computing time on a Cloud computing service provider or install on a local Cloud, where they
can create VM server instances from the archived snapshots. Furthermore for users lacking access to 
local compute clusters and are strained for funds to cover the informatics costs, renting a VM from 
Cloud providers for data analysis and then creating compressed snapshots to reduce costs for long-term 
storage, offers an economical and flexible solution throughout and past the life cycle of a research project.

Finally, leveraging virtualization and VM technology can provide two additional advantages: first, 
by placing data and pre-configured software on a publicly accessible, Cloud-based VM, allows for easy 
reproducibility of the performed bioinformatic data analysis. For example, following publication of 
assembly and annotation results from a genome sequencing project, researchers in the community can re-run
part of the bioinformatic analysis and change algorithmic parameters to fine tune outputs such as 
gene predictions. By lowering the barriers of technical expertise and access to informatics resources 
required for performing bioinformatics computing is a key aspect for researchers to extract value 
from the data released from sequencing projects, while also allowing the community to build additional 
value on top of available data as similar studies take place. Second, researchers have the capability 
to scale computational resources based on the amount of data generated within a sequencing project, 
through provision of an appropriate number of VM servers on the Cloud or local compute hardware. In this
case usage of resources can be scaled accordingly during the different analysis phases: while 
initially extensive computing resources will be necessary to perform assembly and annotation of the sequence 
data, the resources (number of VM servers) can be reduced for the less computationally intensive tasks such 
as summarization and visualization of the sequence annotations. After funding has ended, a lab can further 
scale down the computational resources and cut its informatics costs by archiving the VMs using Whole 
System Snapshots \cite{Dudley2010}.



\subsubsection*{What the Public, Private, Open-Source or Commercial Clouds Available to Biologists Today ?} 

Amazon Web Services (ref) is one of the largest cloud computing vendors, providing a compute cloud  based on the same infrastructure which powers Amazon's e-commerce web sites, executing millions of transactions monthly for their customers. From their cloud computing offering, services that can be utilized to build Science as a Service application include the Amazon Elastic Compute cloud (EC2),  Elastic Block Store and Simple Storage Service (S3), and SimpleDB. These web services offer respectively compute cycles, data storage and database functionality, and are not tied to any specific operating system, or programming model. A large developer community with a lot of expertise exists around each type of the Amazon Web Services (dev. forums ref) mentioned above, and from our experience technical issues with the services for which questions where posted on the forums, were answered in a day or less.

A large capacity server with 64GB memory and 8 processor 
(CPU) cores for example, that would suffice for most types of bioinformatic analysis costs \$2 US to rent per hour 
on Amazon EC2 \cite{ec2price}, and researchers worldwide can rent if required a number of servers for large-scale 
data analysis. 

ur system will not be limited only to the Amazon EC2 Cloud platform, since researchers that have access to a
local cluster at their home institution will have the option to download the VM and run, without being
required to perform any software installation.  The only dependency will be a virtualization layer that can
run the VM on the cluster such as for example the OpenStack open-source Cloud (http://www.openstack.org).
OpenStack is available as part of widely used Ubuntu Linux (http://www.ubuntu.com/Cloud) and included by
default on a compute cluster set-up to run this operating system, while it can be easily installed as a
package on clusters running other Linux versions. Alternatively, for researchers that do not have access to
local compute Clouds, OpenStack installations can be accessed through the government-funded Argonne National
Lab Magellan Cloud http://www.alcf.anl.gov/magellan) that provides compute allocations to researchers, in
addition to a number of academic computing centers in both the US and abroad
(http://openstack.org/user-stories/), or commercial Cloud providers such as RackSpace.

Alternatively, 
researchers with access to data centers at their home institutions, have also the option to download 
and run a VM on a private Cloud such as Eucalyptus \cite{euca} or OpenStack \cite{openstack} that 
are open-source replicas of Amazon EC2. Nonetheless, even in this case researchers are not required
to configure software since everything comes pre-installed and ready-to-execute in the VM, allowing 
them to leverage available bioinformatics tools and data analysis pipelines with minimal effort \cite{Krampis2012}.

VM servers with the pre-configured pipelines and data will be publicly available for download. Researchers
will have the option to execute them on a desktop computer, using virtualization software such as VirtualBox
(http://www.virtualbox.org). VirtualBox is free and can be installed with a single step on Windows, Mac or
Linux desktop computers.  Alternatively, research teams with informatics expertise and access to a local
cluster could choose to download our VM servers and perform large-scale data analysis by running them on a
private Cloud installation, after installing Eucalyptus or OpenStack and converting part of the cluster to a
local Cloud. 

Data storage using a Cloud service has the advantage that large-scale sequencing datasets can be easily
exchanged among collaborators worldwide. Inherent in the design of Amazon S3 (http://aws.amazon.com/s3)
service is replication of data across several physical storage locations for disaster prevention, available
currently on US East and West regions, European Union (Ireland) and Asia Pacific (Singapore). For the data
upload a researcher can choose the closest region for minimizing data transfer latency over the internet.
Following that, the Cloud service automatically replicates the data to different locations as part of the
disaster prevention policy, allowing collaborating researchers to download the data from their closest region.

Currently Amazon S3 has offers a community program (http://aws.amazon.com/datasets) to host a variety of
widely used public datasets at no charge for  researchers.  Bioinformatics-related datasets hosted for free
come from the 1000 human genomes, the complete Genbank, Ensembl and Unigene databases, in addition to the
Ensembl human genome annotation data. public data Researchers can then access, copy, modify and perform
computation on these data volumes directly using pre-configured VMs on Amazon EC2 instances such as JCVI's
Cloud Biolinux, and just pay for the compute and additional storage resources they use. We are in negotiations
with Amazon to get support for hosting the data from this project as part of this program.


\subsubsection*{Software or Infrastructure as A Service on the Cloud ?}

Can Non-Computationally Savvy Researchers Access Cloud Informatics Infrastructures? 


Software as a Service (SaaS, \cite{papazoglou2003}) ready to execute, but users have minimal control.

The work for creating JCVI's Cloud BioLinux, was to offer software tools to the bioinformatics community was driven by our vision of 
A concept of Science as a Service (ScaaS) for computational analysis of scientific datasets, could be easily 
defined along the lines of the well established model of Software as a Service (SaaS, \cite{papazoglou2003}), 
where a provider offers pre-installed and configured applications on a local or remote data centers. Users of 
ScaaS do not need to provision any computer hardware other than a desktop computer and a network connection, 
which can lead to significant cost savings especially in the case of applications involving only occasional 
large-scale computations that cannot justify significant investment in hardware. Users simply access the 
software through a browser or a desktop client application that connects to a remote server Application 
Programming Interface (API), do not need need expertise for performing specialized installations, configuration 
or upgrades that are all taken care by the SaaS provider.  

The need for Science as a Service (ScaaS) model for performing scientific computing, is most apparent in the 
bioinformatics community, where there is significant fragmentation of access methods for both software and datasets 
\cite{stein}. While some individual laboratories for example set-up websites that provide online access to the 
tools, or researchers can use mainstream applications such as BLAST \cite{altchul} through centralized portals
such as NCBI \cite{}, much of the software developed as part of publicly funded research is available as source 
code for download and datasets as compressed files on FTP sites. All these options have significant disadvantages,  
such as servers with fixed computational capacity posing a limitation on the dataset size that can be processed. 
This puts the burden to scientists for provisioning computational infrastructure and technical expertise to compile
software and perform complex installation procedures, while also in some cases need access to high performance computing 
servers for specialized bioinformatics tasks such as genome assembly. In the current work we combined the convenience 
of SaaS for end-users with the power of cloud computing, in order to bring pre-installed specialized bioinformatics application which need large computational capacity such as those for genome assembly.


During the past year, both public and commercial offerings pre-configured sequence analysis applications on
the Cloud have become available. On the commercial side, DNAnexus (online ref.  3) currently includes tools
for ChiPseq, RNAseq, 3'-end sequencing for expression quantification (3SEQ) and enzyme restriction analysis.
DNAnexus runs on the Amazon Elastic Compute Cloud (EC2, online ref. 4), which provides on-demand virtual
servers with various compute capacities. Another offering is iNquiry, which is a port to the Cloud of the
bioinformatics software suite that used to be bundled together with the computer clusters built by the BioTeam
(online ref. 5), but is no longer maintained. This platform is essentially a web-server for pre-installed
open-source tools such as EMBOSS, HMMER, BLAST and the R statistical package, also on the EC2 Cloud platform.
And many consulting firms such as cycle computing and BioTeam provide custom solutions at high cost.

Illumina, Broad cloud, what else ?

Infrastructure as a Service (IaaS, \cite{}) users have more control but more flexibility to customize resources
to their needs.

A user can start and access the OSMF Frame VM instance in three simple steps by using the Amazon EC2 cloud console graphical user interface that is accessible via a web browser: first the user signs up for an Amazon EC2 account and after she obtains the credentials logins to the cloud console (http://aws.amazon.com/console);  within the Amazon console the users clicks the “Launch Instance Wizard” button and specifies the OSMF Frame VM volume identifier (our project website will provide the VM identifier for the most recent update, but the latest VM will be also identifiable by the meta-data added to the volume); following the steps of the wizard within the web browser the users selects computational capacity and storage for the OSMF VM, and specifies a username and password for the OSMF WebInterface login (Fig.1, additional users can be created after the initial login); finally, once the wizard steps are complete and the VM status shows “running”, the user copies the assigned URL address of the VM from the Amazon cloud console in a new web browser window in order to access the OSMF interface. The process of starting a VM on the cloud and connecting to it has been documented for the JCVI Cloud BioLinux VM instances (REF), but nonetheless more detailed documentation, video tutorials and user support will be available from the proposed project's website and discussion forum (see Education & Outreach section).


For researchers that would like to leverage the advantages of a VM with the pre-installed assembly portal for
working with the completed assemblies but consider the public Cloud as not secure option, we will offer the
alternative of returning to them by mail an external hard drive with a VM containing with the portal and
assembly data. Users will then be able to load and execute the VM on a local computer cluster with a
Eucalyptus/OpenStack Cloud or on a PC using Virtualbox. We are currently offering a similar solution with
Cloud BioLinux [3], where the project's VM is available for download and execution on a local Cloud or a PC
from our website [4].  Upon local execution of a VM users will simply need to point their browser to the
portal's Internet or local IP address [55] assigned automatically by either the Cloud or Virtualbox (Fig.1B).
The IP address is available through each Cloud platform's or the Virtualbox software administrative
interface, and we will provide extensive documentation (see subsequent paragraph) on uploading, running and
accessing a local VM on the different platforms by extending the available Cloud BioLinux project
documentation.

An intuitive \cite{youtube}
our VM with the pre-installed tools on the Amazon EC2 Cloud, they will only need to follow four simple steps
through their web browser: visit the Amazon Cloud website and create a new account, start the VM execution
wizard through the Cloud's control console [58], choose computational capacity for the VM (memory,
processor, cores, storage capacity), and specify username and password credentials for accessing the running
VM. Each running VM receives a unique web address, and by using their web browser to access the address, a
researcher can login to the portal interface with the assembly tools. These four steps are described in detail
in our Cloud BioLinux publication and the project's documentation [59].


\subsubsection*{Which Factors Challenge Adoption of Cloud-Based Solutions for Bioinformatics }

Another important concern for Cloud-based bioinformatic tools is related to the data transfer bottleneck from
the local sequencing machines to the Cloud servers.  According to the data published for the Amazon Cloud
platform (online ref.11), 600GB of data would require approximately one week to upload on to the remote Cloud
servers, when using an average broadband connection of 10Mbps. With a faster T3 connection which is usually
easily obtainable even at small research institutions, within one week 2TB of data can be uploaded or
approximately 600GB in 2 days.  Solutions addressing this issue are available both as software that maximizes
data transfer over the network compared to traditional File Transfer Protocol (FTP), or physical disk drive
import/export services offered by the Cloud provider to its customers. Aspera's server (online ref. 12) has
been recently integrated to NCBI's infrastructure, and researchers can download a free client that allows
increased upload speeds to the Short Read Archive (online ref. 13).  Through the Aspera software, transfer
bandwidth between NCBI and the European Bioinformatics Institute for data sharing in the 1000 Genomes Project,
has been increased from 20Mbps to 1000Mbps (see online ref. 14). 

Finally, the Amazon offers the option for its users to physically ship disk drives to the company's offices
and have the data copied to their servers (online ref. 11). With only 80 import cost for disk drives up to 4TB
of data (4000GB), this is the most efficient method if we take into account the charge by Amazon for 0.10 per
GB of bandwith consumed, which would add up to 60 for a 600GB data upload. In addition to that cost, the
expense for obtaining a high-bandwidth internet connection for the data upload should be taken into account.
We expect the Microsoft Azure Cloud platform to offer a similar service in the near future, given the requests
on the Azure developer forums and the immediate consideration of the matter by Microsoft (online ref. 15).



%%%%%%%%%%%%%%%%%%%%%%
\section*{Conclusions} Text for this section \ldots



%%%%%%%%%%%%%%%%%%
\section*{Methods} \subsubsection*{Methods sub-heading for this section} Text for this sub-section \ldots

\subsubsection*{Another methods sub-heading for this section} Text for this sub-section \ldots

\subsubsection*{Yet another sub-heading for this section} Text for this sub-section \ldots



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Authors contributions} Text for this section \ldots



%%%%%%%%%%%%%%%%%%%%%%%%%%%
\section*{Acknowledgements} \ifthenelse{\boolean{publ}}{\small}{} Text for this section \ldots



%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%
%%                  The Bibliography                       %%
%%                                                         %%              
%%  Bmc_article.bst  will be used to                       %%
%%  create a .BBL file for submission, which includes      %%
%%  XML structured for BMC.                                %%
%%                                                         %%
%%                                                         %%
%%  Note that the displayed Bibliography will not          %% 
%%  necessarily be rendered by Latex exactly as specified  %%
%%  in the online Instructions for Authors.                %% 
%%                                                         %%
%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%%


{\ifthenelse{\boolean{publ}}{\footnotesize}{\small} \bibliographystyle{bmc_article}  % Style BST file
\bibliography{bmc_article} }     % Bibliography file (usually '*.bib') 

%%%%%%%%%%%

\ifthenelse{\boolean{publ}}{\end{multicols}}{}


\end{bmcformat} \end{document}







